{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport pydicom\nimport os\nimport collections\nimport sys\nimport glob\nimport random\nimport cv2\nimport tensorflow as tf\nimport multiprocessing\n\nfrom math import ceil, floor\nfrom copy import deepcopy\nfrom tqdm import tqdm_notebook as tqdm\nfrom imgaug import augmenters as iaa\n\nimport keras\nimport keras.backend as K\nfrom keras.callbacks import Callback, ModelCheckpoint\nfrom keras.layers import Dense, Flatten, Dropout\nfrom keras.models import Model, load_model\nfrom keras.utils import Sequence\nfrom keras.losses import binary_crossentropy\nfrom keras.optimizers import Adam","execution_count":1,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install efficientnet\n!pip install iterative-stratification","execution_count":2,"outputs":[{"output_type":"stream","text":"Collecting efficientnet\n  Downloading https://files.pythonhosted.org/packages/97/82/f3ae07316f0461417dc54affab6e86ab188a5a22f33176d35271628b96e0/efficientnet-1.0.0-py3-none-any.whl\nRequirement already satisfied: scikit-image in /opt/conda/lib/python3.6/site-packages (from efficientnet) (0.16.2)\nRequirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /opt/conda/lib/python3.6/site-packages (from efficientnet) (1.0.8)\nRequirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->efficientnet) (3.0.3)\nRequirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->efficientnet) (2.4)\nRequirement already satisfied: pillow>=4.3.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->efficientnet) (5.4.1)\nRequirement already satisfied: PyWavelets>=0.4.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->efficientnet) (1.1.1)\nRequirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->efficientnet) (2.6.1)\nRequirement already satisfied: scipy>=0.19.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->efficientnet) (1.4.1)\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.6/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.18.1)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (2.9.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (0.10.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (1.1.0)\nRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.4.5)\nRequirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.8.1)\nRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.6/site-packages (from networkx>=2.0->scikit-image->efficientnet) (4.4.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.13.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (42.0.2.post20191203)\nInstalling collected packages: efficientnet\nSuccessfully installed efficientnet-1.0.0\nCollecting iterative-stratification\n  Downloading https://files.pythonhosted.org/packages/9d/79/9ba64c8c07b07b8b45d80725b2ebd7b7884701c1da34f70d4749f7b45f9a/iterative_stratification-0.1.6-py3-none-any.whl\nRequirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages (from iterative-stratification) (1.4.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from iterative-stratification) (1.18.1)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.6/site-packages (from iterative-stratification) (0.21.3)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->iterative-stratification) (0.14.1)\nInstalling collected packages: iterative-stratification\nSuccessfully installed iterative-stratification-0.1.6\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import Custom Modules\nimport efficientnet.keras as efn \nfrom iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Seed\nSEED = 12345\nnp.random.seed(SEED)\n#tf.set_random_seed(SEED)\ntf.random.set_seed(SEED)\n\n# Constants\nTEST_SIZE = 0.02\nHEIGHT = 256\nWIDTH = 256\nCHANNELS = 3\nTRAIN_BATCH_SIZE = 32\nVALID_BATCH_SIZE = 64\nSHAPE = (HEIGHT, WIDTH, CHANNELS)\n\n# Folders\nDATA_DIR = '/kaggle/input/new-csvs/'\nDATA_DIR2 = '/kaggle/input/rsna-intracranial-hemorrhage-detection/rsna-intracranial-hemorrhage-detection/'\nTEST_IMAGES_DIR = DATA_DIR2 + 'stage_2_test/'\nTRAIN_IMAGES_DIR = DATA_DIR2 + 'stage_2_train/'","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def correct_dcm(dcm):\n    x = dcm.pixel_array + 1000\n    px_mode = 4096\n    x[x>=px_mode] = x[x>=px_mode] - px_mode\n    dcm.PixelData = x.tobytes()\n    dcm.RescaleIntercept = -1000\n\ndef window_image(dcm, window_center, window_width):    \n    if (dcm.BitsStored == 12) and (dcm.PixelRepresentation == 0) and (int(dcm.RescaleIntercept) > -100):\n        correct_dcm(dcm)\n    img = dcm.pixel_array * dcm.RescaleSlope + dcm.RescaleIntercept\n    \n    # Resize\n    img = cv2.resize(img, SHAPE[:2], interpolation = cv2.INTER_LINEAR)\n   \n    img_min = window_center - window_width // 2\n    img_max = window_center + window_width // 2\n    img = np.clip(img, img_min, img_max)\n    return img\n\ndef bsb_window(dcm):\n    brain_img = window_image(dcm, 40, 80)\n    subdural_img = window_image(dcm, 80, 200)\n    soft_img = window_image(dcm, 40, 380)\n    \n    brain_img = (brain_img - 0) / 80\n    subdural_img = (subdural_img - (-20)) / 200\n    soft_img = (soft_img - (-150)) / 380\n    bsb_img = np.array([brain_img, subdural_img, soft_img]).transpose(1,2,0)\n    return bsb_img\n\ndef _read(path, SHAPE):\n    dcm = pydicom.dcmread(path)\n    try:\n        img = bsb_window(dcm)\n    except:\n        img = np.zeros(SHAPE)\n    return img","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Image Augmentation\nsometimes = lambda aug: iaa.Sometimes(0.25, aug)\naugmentation = iaa.Sequential([ iaa.Fliplr(0.25),\n                                iaa.Flipud(0.10),\n                                sometimes(iaa.Crop(px=(0, 25), keep_size = True, sample_independently = False))   \n                            ], random_order = True)       \n        \n# Generators\nclass TrainDataGenerator(keras.utils.Sequence):\n    def __init__(self, dataset, labels, batch_size = 16, img_size = SHAPE, img_dir = TRAIN_IMAGES_DIR, augment = False, *args, **kwargs):\n        self.dataset = dataset\n        self.ids = dataset.index\n        self.labels = labels\n        self.batch_size = batch_size\n        self.img_size = img_size\n        self.img_dir = img_dir\n        self.augment = augment\n        self.on_epoch_end()\n\n    def __len__(self):\n        return int(ceil(len(self.ids) / self.batch_size))\n\n    def __getitem__(self, index):\n        indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n        X, Y = self.__data_generation(indices)\n        return X, Y\n\n    def augmentor(self, image):\n        augment_img = augmentation        \n        image_aug = augment_img.augment_image(image)\n        return image_aug\n\n    def on_epoch_end(self):\n        self.indices = np.arange(len(self.ids))\n        np.random.shuffle(self.indices)\n\n    def __data_generation(self, indices):\n        X = np.empty((self.batch_size, *self.img_size))\n        Y = np.empty((self.batch_size, 6), dtype=np.float32)\n        \n        for i, index in enumerate(indices):\n            ID = self.ids[index]\n            image = _read(self.img_dir+ID+\".dcm\", self.img_size)\n            if self.augment:\n                X[i,] = self.augmentor(image)\n            else:\n                X[i,] = image\n            Y[i,] = self.labels.iloc[index].values        \n        return X, Y\n    \nclass TestDataGenerator(keras.utils.Sequence):\n    def __init__(self, dataset, labels, batch_size = 16, img_size = SHAPE, img_dir = TEST_IMAGES_DIR, *args, **kwargs):\n        self.dataset = dataset\n        self.ids = dataset.index\n        self.labels = labels\n        self.batch_size = batch_size\n        self.img_size = img_size\n        self.img_dir = img_dir\n        self.on_epoch_end()\n\n    def __len__(self):\n        return int(ceil(len(self.ids) / self.batch_size))\n\n    def __getitem__(self, index):\n        indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n        X = self.__data_generation(indices)\n        return X\n\n    def on_epoch_end(self):\n        self.indices = np.arange(len(self.ids))\n    \n    def __data_generation(self, indices):\n        X = np.empty((self.batch_size, *self.img_size))\n        \n        for i, index in enumerate(indices):\n            ID = self.ids[index]\n            image = _read(self.img_dir+ID+\".dcm\", self.img_size)\n            X[i,] = image              \n        return X","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_testset(filename = DATA_DIR + \"stage_2_sample_submission.csv\"):\n    df = pd.read_csv(filename)\n    df[\"Image\"] = df[\"ID\"].str.slice(stop=12)\n    df[\"Diagnosis\"] = df[\"ID\"].str.slice(start=13)\n    df = df.loc[:, [\"Label\", \"Diagnosis\", \"Image\"]]\n    df = df.set_index(['Image', 'Diagnosis']).unstack(level=-1)\n    return df\n\ndef read_trainset(filename = DATA_DIR + \"stage_2_train.csv\"):\n    df = pd.read_csv(filename)\n    df[\"Image\"] = df[\"ID\"].str.slice(stop=12)\n    df[\"Diagnosis\"] = df[\"ID\"].str.slice(start=13)\n\n    df = df.reset_index(drop = True)    \n    df = df.loc[:, [\"Label\", \"Diagnosis\", \"Image\"]]\n    df = df.set_index(['Image', 'Diagnosis']).unstack(level=-1)\n    return df\n\n# Read Train and Test Datasets\ntest_df = read_testset()\ntrain_df = read_trainset()","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head(10)","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"             Label                                                          \\\nDiagnosis      any epidural intraparenchymal intraventricular subarachnoid   \nImage                                                                        \nID_000176f2a   0.5      0.5              0.5              0.5          0.5   \nID_00033386d   0.5      0.5              0.5              0.5          0.5   \nID_000357857   0.5      0.5              0.5              0.5          0.5   \nID_0007656c5   0.5      0.5              0.5              0.5          0.5   \nID_000a2d7b0   0.5      0.5              0.5              0.5          0.5   \nID_000a50137   0.5      0.5              0.5              0.5          0.5   \nID_000cd1921   0.5      0.5              0.5              0.5          0.5   \nID_000cef503   0.5      0.5              0.5              0.5          0.5   \nID_000d2b631   0.5      0.5              0.5              0.5          0.5   \nID_0010cc011   0.5      0.5              0.5              0.5          0.5   \n\n                       \nDiagnosis    subdural  \nImage                  \nID_000176f2a      0.5  \nID_00033386d      0.5  \nID_000357857      0.5  \nID_0007656c5      0.5  \nID_000a2d7b0      0.5  \nID_000a50137      0.5  \nID_000cd1921      0.5  \nID_000cef503      0.5  \nID_000d2b631      0.5  \nID_0010cc011      0.5  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"6\" halign=\"left\">Label</th>\n    </tr>\n    <tr>\n      <th>Diagnosis</th>\n      <th>any</th>\n      <th>epidural</th>\n      <th>intraparenchymal</th>\n      <th>intraventricular</th>\n      <th>subarachnoid</th>\n      <th>subdural</th>\n    </tr>\n    <tr>\n      <th>Image</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>ID_000176f2a</th>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>ID_00033386d</th>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>ID_000357857</th>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>ID_0007656c5</th>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>ID_000a2d7b0</th>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>ID_000a50137</th>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>ID_000cd1921</th>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>ID_000cef503</th>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>ID_000d2b631</th>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>ID_0010cc011</th>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head(10)","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"             Label                                                          \\\nDiagnosis      any epidural intraparenchymal intraventricular subarachnoid   \nImage                                                                        \nID_000012eaf   0.0      0.0              0.0              0.0          0.0   \nID_00061f33d   0.0      0.0              0.0              0.0          0.0   \nID_00086a66f   0.0      0.0              0.0              0.0          0.0   \nID_000b53a57   0.0      0.0              0.0              0.0          0.0   \nID_000b64471   0.0      0.0              0.0              0.0          0.0   \nID_000bd98e8   0.0      0.0              0.0              0.0          0.0   \nID_000edbf38   1.0      1.0              0.0              0.0          0.0   \nID_000fd6d15   0.0      0.0              0.0              0.0          0.0   \nID_001033b29   0.0      0.0              0.0              0.0          0.0   \nID_0010d3d82   0.0      0.0              0.0              0.0          0.0   \n\n                       \nDiagnosis    subdural  \nImage                  \nID_000012eaf      0.0  \nID_00061f33d      0.0  \nID_00086a66f      0.0  \nID_000b53a57      0.0  \nID_000b64471      0.0  \nID_000bd98e8      0.0  \nID_000edbf38      0.0  \nID_000fd6d15      0.0  \nID_001033b29      0.0  \nID_0010d3d82      0.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"6\" halign=\"left\">Label</th>\n    </tr>\n    <tr>\n      <th>Diagnosis</th>\n      <th>any</th>\n      <th>epidural</th>\n      <th>intraparenchymal</th>\n      <th>intraventricular</th>\n      <th>subarachnoid</th>\n      <th>subdural</th>\n    </tr>\n    <tr>\n      <th>Image</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>ID_000012eaf</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>ID_00061f33d</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>ID_00086a66f</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>ID_000b53a57</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>ID_000b64471</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>ID_000bd98e8</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>ID_000edbf38</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>ID_000fd6d15</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>ID_001033b29</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>ID_0010d3d82</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.sum()","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"       Diagnosis       \nLabel  any                 4710.0\n       epidural             144.0\n       intraparenchymal    1590.0\n       intraventricular    1155.0\n       subarachnoid        1513.0\n       subdural            2063.0\ndtype: float64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Oversampling (existem pouca amostra epidural)\nepidural_df = train_df[train_df.Label['epidural'] == 1]\ntrain_oversample_df = pd.concat([train_df, epidural_df])\ntrain_df = train_oversample_df\n\nepidural_df = train_df[train_df.Label['epidural'] == 1]\ntrain_oversample_df = pd.concat([train_df, epidural_df])\ntrain_df = train_oversample_df\n\nepidural_df = train_df[train_df.Label['epidural'] == 1]\ntrain_oversample_df = pd.concat([train_df, epidural_df])\ntrain_df = train_oversample_df\n\n# Summary\nprint('Train Shape: {}'.format(train_df.shape))\nprint('Test Shape: {}'.format(test_df.shape))","execution_count":12,"outputs":[{"output_type":"stream","text":"Train Shape: (34342, 6)\nTest Shape: (33334, 6)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.sum()","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"       Diagnosis       \nLabel  any                 5718.0\n       epidural            1152.0\n       intraparenchymal    1772.0\n       intraventricular    1232.0\n       subarachnoid        1744.0\n       subdural            2259.0\ndtype: float64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predictions(test_df, model):    \n    test_preds = model.predict_generator(TestDataGenerator(test_df, None, 8, SHAPE, TEST_IMAGES_DIR), verbose = 1)\n    return test_preds[:test_df.iloc[range(test_df.shape[0])].shape[0]]\n\ndef ModelCheckpointFull(model_name):\n    return ModelCheckpoint(model_name, \n                            monitor = 'val_loss', \n                            verbose = 1, \n                            save_best_only = False, \n                            save_weights_only = True, \n                            mode = 'min', \n                            period = 1)\n\n# Create Model\ndef create_model():\n    K.clear_session()\n    \n    base_model =  efn.EfficientNetB2(weights = 'imagenet', include_top = False, pooling = 'avg', input_shape = SHAPE)\n    x = base_model.output\n    x = Dropout(0.15)(x)\n    y_pred = Dense(6, activation = 'sigmoid')(x)\n\n    return Model(inputs = base_model.input, outputs = y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" train_df.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Submission Placeholder\nsubmission_predictions = []\n\n# Multi Label Stratified Split stuff...\nmsss = MultilabelStratifiedShuffleSplit(n_splits = 10, test_size = TEST_SIZE, random_state = SEED)\nX = train_df.index\nY = train_df.Label.values\n\n# Get train and test index\nmsss_splits = next(msss.split(X, Y))\ntrain_idx = msss_splits[0]\nvalid_idx = msss_splits[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loop through Folds of Multi Label Stratified Split\nfor epoch, msss_splits in zip(range(0, 9), msss.split(X, Y)): \n#    # Get train and test index\n    train_idx = msss_splits[0]\n    valid_idx = msss_splits[1]\nfor epoch in range(0, 3):\n    print('=========== EPOCH {}'.format(epoch))\n\n    # Shuffle Train data\n    np.random.shuffle(train_idx)\n    print(train_idx[:5])    \n    print(valid_idx[:5])\n\n    # Create Data Generators for Train and Valid\n    data_generator_train = TrainDataGenerator(train_df.iloc[train_idx], \n                                                train_df.iloc[train_idx], \n                                                TRAIN_BATCH_SIZE, \n                                                SHAPE,\n                                                augment = True)\n    data_generator_val = TrainDataGenerator(train_df.iloc[valid_idx], \n                                            train_df.iloc[valid_idx], \n                                            VALID_BATCH_SIZE, \n                                            SHAPE,\n                                            augment = False)\n\n    # Create Model\n    model = create_model()\n    \n    # Full Training Model\n    for base_layer in model.layers[:-1]:\n        base_layer.trainable = True\n    TRAIN_STEPS = int(len(data_generator_train) / 6)\n    LR = 0.000125\n\n    if epoch != 0:\n        # Load Model Weights\n        model.load_weights('model.h5') \n    \n    #runoptions aqui \n    #run_opts = tf.compat.v1.RunOptions(report_tensor_allocations_upon_oom = True)\n\n    model.compile(optimizer = Adam(learning_rate = LR), \n                  loss = 'binary_crossentropy',\n                  metrics = ['acc', tf.keras.metrics.AUC()])\n    \n    # Train Model\n    model.fit_generator(generator = data_generator_train,\n                        validation_data = data_generator_val,\n                        steps_per_epoch = TRAIN_STEPS,\n                        epochs = 1,\n                        callbacks = [ModelCheckpointFull('model.h5')],\n                        verbose = 1)\n    \n    # Starting with the 4th epoch we create predictions for the test set on each epoch\n    if epoch >= 1:\n        preds = predictions(test_df, model)\n        submission_predictions.append(preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.iloc[:, :] = np.average(submission_predictions, axis = 0, weights = [2**i for i in range(len(submission_predictions))])\ntest_df = test_df.stack().reset_index()\ntest_df.insert(loc = 0, column = 'ID', value = test_df['Image'].astype(str) + \"_\" + test_df['Diagnosis'])\ntest_df = test_df.drop([\"Image\", \"Diagnosis\"], axis=1)\ntest_df.to_csv('submission.csv', index = False)\nprint(test_df.head(12))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"file_extension":".py","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"nbformat":4,"nbformat_minor":1}